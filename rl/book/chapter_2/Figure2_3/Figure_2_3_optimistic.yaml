num_episodes: 2000
num_iterations: 1000
out_image: ArmedBandits
env_name: BanditTenArmedGaussian-v0
arms: 10

nonstationary: {
  mu: 0,
  sigma: 0.01
}

agents: [
{
  policy: "Egreedy",
  learning: "WeightedAveraging",
  optimistic: 5
    kwargs: {
      exploratory_rate: 0.0,
      learning_rate: 0.1,
    }
},
{
  policy: "EGreedy",
  learning: "WeightedAveraging",
  kwargs: {
    exploratory_rate: 0.1,
    learning_rate: 0.1,
  }
},
]