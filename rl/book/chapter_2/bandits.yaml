num_episodes: 200
num_iterations: 1000
out_image: ArmedBandits
env_name: BanditTenArmedGaussian-v0
arms: 10

nonstationary: {
  mu: 0,
  sigma: 0.1
}

agents: [
{
  policy: "UpperConfidenceBound",
  learning: "WeightedAveraging",
  kwargs: {
    decay_rate: 0.99,
    confidence: 1,
    learning_rate: 0.1,
  }
},
{
  policy: "DecayingEGreedy",
  learning: "WeightedAveraging",
  kwargs: {
    decay_rate: 0.5 ,
    exploratory_rate: 0.1,
    learning_rate: 0.1,
  }
},
{
  policy: "EGreedy",
  learning: "WeightedAveraging",
  kwargs: {
    exploratory_rate: 0.1,
    learning_rate: 0.1,
  }
},
{
  policy: "EGreedy",
  learning: "WeightedAveraging",
  optimistic: 5,
  kwargs: {
    exploratory_rate: 0.0,
    learning_rate: 0.1,
  }
},
{
  policy: "Random",
  learning: "WeightedAveraging",
  kwargs: {
    learning_rate: 0.1,
  }
},
]