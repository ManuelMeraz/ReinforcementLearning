num_episodes: 200
num_iterations: 1000
out_image: ArmedBandits
env_name: BanditTenArmedGaussian-v0
arms: 10

nonstationary: {
  mu: 0,
  sigma: 0.01
}

agents: [
{
  policy: "EGreedy",
  learning: "WeightedAveraging",
  optimistic: 5,
  kwargs: {
    exploratory_rate: 0.0,
    learning_rate: 0.1,
  }
},
{
  policy: "EGreedy",
  learning: "WeightedAveraging",
  optimistic: 0,
  kwargs: {
    exploratory_rate: 0.01,
    learning_rate: 0.1,
  }
},
{
  policy: "EGreedy",
  learning: "WeightedAveraging",
  optimistic: 0,
  kwargs: {
    exploratory_rate: 0.1,
    learning_rate: 0.1,
  }
},
]