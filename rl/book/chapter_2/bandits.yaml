num_episodes: 100
num_iterations: 10000
out_image: ArmedBandits
env_name: BanditTenArmedGaussian-v0
arms: 10

nonstationary: {
  mu: 0,
  sigma: 0.1
}

agents: [
{
  policy: "UpperConfidenceBound",
  learning: "WeightedAveraging",
  kwargs: {
    confidence: 0.1,
    learning_rate: 0.1,
  }
},
{
  policy: "UpperConfidenceBound",
  learning: "WeightedAveraging",
  kwargs: {
    confidence: 1,
    learning_rate: 0.1,
  }
},
{
  policy: "UpperConfidenceBound",
  learning: "WeightedAveraging",
  kwargs: {
    confidence: 10,
    learning_rate: 0.1,
  }
},
{
  policy: "UpperConfidenceBound",
  learning: "WeightedAveraging",
  kwargs: {
    confidence: 20,
    learning_rate: 0.1,
  }
},
{
  policy: "UpperConfidenceBound",
  learning: "WeightedAveraging",
  kwargs: {
    confidence: 50,
    learning_rate: 0.1,
  }
},
{
  policy: "UpperConfidenceBound",
  learning: "WeightedAveraging",
  kwargs: {
    confidence: 100,
    learning_rate: 0.1,
  }
},
{
  policy: "UpperConfidenceBound",
  learning: "WeightedAveraging",
  kwargs: {
    confidence: 1000,
    learning_rate: 0.1,
  }
},
{
  policy: "EGreedy",
  learning: "WeightedAveraging",
  kwargs: {
    exploratory_rate: 0.1,
    learning_rate: 0.1,
  }
},
]